---
---


@inproceedings{cdm,
    title = "An Electoral Approach to Diversify LLM-based Multi-Agent Collective Decision-Making",
    author = "Zhao, Xiutian  and
      Wang, Ke  and
      Peng, Wei",
    booktitle = "Accepted by Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://openreview.net/forum?id=L5cgN9UKnk",
}

@inproceedings{xiong2024watchstepllmagent,
    title={Watch Every Step! LLM Agent Learning via Iterative Step-Level Process Refinement},
    author={Weimin Xiong and Yifan Song and Xiutian Zhao and Wenhao Wu and Xun Wang and Ke Wang and Cheng Li and Wei Peng and Sujian Li},
    booktitle = "Accepted by Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://arxiv.org/abs/2406.11176",
}

@inproceedings{agentbank,
    title = "AgentBank: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories",
    author = "Song, Yifan  and
      Xiong, Weiming  and
      Zhao, Xiutian  and
    Zhu, Dawei and
    Wu, Wenhao and
    Wang, Ke and
    Li, Cheng and
    Peng, Wei and
    Li, Sujian",
    booktitle = "Accepted by Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://openreview.net/forum?id=P8URqRlQD0",
}

@inproceedings{zhao-etal-2024-measuring,
    title = "Measuring the Inconsistency of Large Language Models in Preferential Ranking",
    author = "Zhao, Xiutian  and
      Wang, Ke  and
      Peng, Wei",
    editor = "Li, Sha  and
      Li, Manling  and
      Zhang, Michael JQ  and
      Choi, Eunsol  and
      Geva, Mor  and
      Hase, Peter  and
      Ji, Heng",
    booktitle = "Proceedings of the 1st Workshop on Towards Knowledgeable Language Models (KnowLLM 2024) @ ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.knowllm-1.14",
    pages = "171--176",
    abstract = "Despite large language models{'} (LLMs{'}) recent advancements, their bias and hallucination issues persist, and their ability to offer consistent and preferential rankings remains underexplored. This study investigates the capacity of LLMs to provide consistent ordinal preferences, a crucial aspect in scenarios lacking absolute answers. We introduce a formalization of consistency based on order theory, outlining criteria such as transitivity, asymmetry, reversibility, and independence from irrelevant alternatives. Our diagnostic experiments on selected state-of-the-art LLMs reveal their inability to meet these criteria, indicating a strong positional bias and poor transitivity, with preferences easily swayed by irrelevant alternatives. These findings highlight a significant inconsistency in LLM-generated preferential rankings, underscoring the need for further research to address these limitations.",
    note="(Oral Session)",
}


@misc{liu2024survey,
      title={A Survey on Hallucination in Large Vision-Language Models},
      author={Liu, Hanchao and Xue, Wenyuan and Chen, Yifei and Chen, Dapeng and Zhao, Xiutian and Wang, Ke and Hou, Liping and Li, Rongjun and Peng, Wei},
      year={2024},month=feb,
      eprint={2402.00253},
      archivePrefix={arXiv},
      abstract="Recent development of Large Vision-Language Models (LVLMs) has attracted growing attention within the AI landscape for its practical implementation potential. However, ``hallucination'', or more specifically, the misalignment between factual visual content and corresponding textual generation, poses a significant challenge of utilizing LVLMs. In this comprehensive survey, we dissect LVLM-related hallucinations in an attempt to establish an overview and facilitate future mitigation. Our scrutiny starts with a clarification of the concept of hallucinations in LVLMs, presenting a variety of hallucination symptoms and highlighting the unique challenges inherent in LVLM hallucinations. Subsequently, we outline the benchmarks and methodologies tailored specifically for evaluating hallucinations unique to LVLMs. Additionally, we delve into an investigation of the root causes of these hallucinations, encompassing insights from the training data and model components. We also critically review existing methods for mitigating hallucinations. The open questions and future directions pertaining to hallucinations within LVLMs are discussed to conclude this survey."
}


@article{Wang_Zhao_Peng_2024,
title={Learning from Failure: Improving Meeting Summarization without Good Samples},
volume={38},
url={https://ojs.aaai.org/index.php/AAAI/article/view/29883},
DOI={10.1609/aaai.v38i17.29883},
abstract="Existing methods aligning language models with various human needs are reliant heavily on high-quality and task-specific data. However, industrial deployment of task-specific language models often encounter challenges in the availability of appropriate training samples. Taking meeting summarization for instance, public datasets are scarce, and private corpora are also hard to obtain due to privacy issues or resource-demanding annotation. To improve meeting summarization in the absence of positively-rated (i.e., ``good’’) samples, we propose Score Tuning, a cold start tuning framework that leverages bad samples of distinguishable degrees to incrementally enhance the performance of summary generation without an initial presence of good samples. Our method utilizes asynchronous and numerical human feedback that measure the quality of generated summaries. Formulating data into triplets of (transcript, summary, score), our approach instructs a pre-trained model to learn the association between summary qualities and human-rated scores and hence to generate better summaries corresponding to higher scores. The experiment results show that our method is effective in improving meeting summarization on both English and Chinese corpora while requiring less annotated data and training resources compared to existing alignment methods. Additionally, we also preliminarily explore the transferability of our approach in machine translation tasks and demonstrate its potential for future development and usage in other domains.",
number={17},
journal={Proceedings of the AAAI Conference on Artificial Intelligence},
author={Wang, Ke and Zhao, Xiutian and Peng, Wei},
year={2024},
month={Mar.},
pages={19153-19161}
}

@inproceedings{zhao-etal-2023-orchid,
    title = "{ORCHID}: A {C}hinese Debate Corpus for Target-Independent Stance Detection and Argumentative Dialogue Summarization",
    author = "Zhao, Xiutian  and
      Wang, Ke  and
      Peng, Wei",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.582",
    pages = "9358--9375",
    abstract = "Dialogue agents have been receiving increasing attention for years, and this trend has been further boosted by the recent progress of large language models (LLMs). Stance detection and dialogue summarization are two core tasks of dialogue agents in application scenarios that involve argumentative dialogues. However, research on these tasks is limited by the insufficiency of public datasets, especially for non-English languages. To address this language resource gap in Chinese, we present ORCHID (Oral Chinese Debate), the first Chinese dataset for benchmarking target-independent stance detection and debate summarization. Our dataset consists of 1,218 real-world debates that were conducted in Chinese on 476 unique topics, containing 2,436 stance-specific summaries and 14,133 fully annotated utterances. Besides providing a versatile testbed for future research, we also conduct an empirical study on the dataset and propose an integrated task. The results show the challenging nature of the dataset and suggest a potential of incorporating stance detection in summarization for argumentative dialogue.",
}

@inproceedings{wang-etal-2023-m3seg,
    title = "{M}$^3${S}eg: A Maximum-Minimum Mutual Information Paradigm for Unsupervised Topic Segmentation in {ASR} Transcripts",
    author = "Wang, Ke  and
      Zhao, Xiutian  and
      Li, Yanghui  and
      Peng, Wei",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.492",
    pages = "7928--7934",
    abstract = "Topic segmentation aims to detect topic boundaries and split automatic speech recognition transcriptions (e.g., meeting transcripts) into segments that are bounded by thematic meanings. In this work, we propose M$^3$Seg, a novel Maximum-Minimum Mutual information paradigm for linear topic segmentation without using any parallel data. Specifically, by employing sentence representations provided by pre-trained language models, M$^3$Seg first learns a region-based segment encoder based on the maximization of mutual information between the global segment representation and the local contextual sentence representation. Secondly, an edge-based boundary detection module aims to segment the whole by topics based on minimizing the mutual information between different segments. Experiment results on two public datasets demonstrate the effectiveness of M$^3$Seg, which outperform the state-of-the-art methods by a significant (18{\%}{--}37{\%} improvement) margin.",
}

@inproceedings{wang-etal-2023-prose,
    title = "{PROSE}: A Pronoun Omission Solution for {C}hinese-{E}nglish Spoken Language Translation",
    author = "Wang, Ke  and
      Zhao, Xiutian  and
      Li, Yanghui  and
      Peng, Wei",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.141",
    pages = "2297--2311",
    abstract = "Neural Machine Translation (NMT) systems encounter a significant challenge when translating a pro-drop ({`}pronoun-dropping{'}) language (e.g., Chinese) to a non-pro-drop one (e.g., English), since the pro-drop phenomenon demands NMT systems to recover omitted pronouns. This unique and crucial task, however, lacks sufficient datasets for benchmarking. To bridge this gap, we introduce PROSE, a new benchmark featured in diverse pro-drop instances for document-level Chinese-English spoken language translation. Furthermore, we conduct an in-depth investigation of the pro-drop phenomenon in spoken Chinese on this dataset, reconfirming that pro-drop reduces the performance of NMT systems in Chinese-English translation. To alleviate the negative impact introduced by pro-drop, we propose Mention-Aware Semantic Augmentation, a novel approach that leverages the semantic embedding of dropped pronouns to augment training pairs. Results from the experiments on four Chinese-English translation corpora show that our proposed method outperforms existing methods regarding omitted pronoun retrieval and overall translation quality.",
}
