---
---


@inproceedings{cdm,
    title = "An Electoral Approach to Diversify LLM-based Multi-Agent Collective Decision-Making",
    author = "Zhao, Xiutian  and
      Wang, Ke  and
      Peng, Wei",
    booktitle = "Accepted by Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://openreview.net/forum?id=L5cgN9UKnk",
}

@inproceedings{xiong2024watchstepllmagent,
    title={Watch Every Step! LLM Agent Learning via Iterative Step-Level Process Refinement},
    author={Weimin Xiong and Yifan Song and Xiutian Zhao and Wenhao Wu and Xun Wang and Ke Wang and Cheng Li and Wei Peng and Sujian Li},
    booktitle = "Accepted by Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://arxiv.org/abs/2406.11176",
}

@inproceedings{agentbank,
    title = "AgentBank: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories",
    author = "Song, Yifan  and
      Xiong, Weiming  and
      Zhao, Xiutian  and
    Zhu, Dawei and
    Wu, Wenhao and
    Wang, Ke and
    Li, Cheng and
    Peng, Wei and
    Li, Sujian",
    booktitle = "Accepted by Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://openreview.net/forum?id=P8URqRlQD0",
}

@inproceedings{zhao-etal-2024-measuring,
    title = "Measuring the Inconsistency of Large Language Models in Preferential Ranking",
    author = "Zhao, Xiutian  and
      Wang, Ke  and
      Peng, Wei",
    editor = "Li, Sha  and
      Li, Manling  and
      Zhang, Michael JQ  and
      Choi, Eunsol  and
      Geva, Mor  and
      Hase, Peter  and
      Ji, Heng",
    booktitle = "Proceedings of the 1st Workshop on Towards Knowledgeable Language Models (KnowLLM 2024)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.knowllm-1.14",
    pages = "171--176",
    abstract = "Despite large language models{'} (LLMs{'}) recent advancements, their bias and hallucination issues persist, and their ability to offer consistent and preferential rankings remains underexplored. This study investigates the capacity of LLMs to provide consistent ordinal preferences, a crucial aspect in scenarios lacking absolute answers. We introduce a formalization of consistency based on order theory, outlining criteria such as transitivity, asymmetry, reversibility, and independence from irrelevant alternatives. Our diagnostic experiments on selected state-of-the-art LLMs reveal their inability to meet these criteria, indicating a strong positional bias and poor transitivity, with preferences easily swayed by irrelevant alternatives. These findings highlight a significant inconsistency in LLM-generated preferential rankings, underscoring the need for further research to address these limitations.",
    note="(Oral Session)"
}


@misc{liu2024survey,
      title={A Survey on Hallucination in Large Vision-Language Models},
      author={Hanchao Liu and Wenyuan Xue and Yifei Chen and Dapeng Chen and Xiutian Zhao and Ke Wang and Liping Hou and Rongjun Li and Wei Peng},
      year={2024},
      eprint={2402.00253},
      archivePrefix={arXiv},
      url = "https://arxiv.org/abs/2402.00253"
      primaryClass={cs.CV}
}


@INPROCEEDINGS{score-tuning,
author={Wang, Ke and Zhao, Xiutian and Peng, Wei},
year={2024},
month = feb,
booktitle={Proceedings of the 38th AAAI Conference on Artificial Intelligence},
title={Learning from Failure: Improving Meeting Summarization without Good Samples},
}

@inproceedings{zhao-etal-2023-orchid,
    title = "{ORCHID}: A {C}hinese Debate Corpus for Target-Independent Stance Detection and Argumentative Dialogue Summarization",
    author = "Zhao, Xiutian  and
      Wang, Ke  and
      Peng, Wei",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.582",
    pages = "9358--9375",
    abstract = "Dialogue agents have been receiving increasing attention for years, and this trend has been further boosted by the recent progress of large language models (LLMs). Stance detection and dialogue summarization are two core tasks of dialogue agents in application scenarios that involve argumentative dialogues. However, research on these tasks is limited by the insufficiency of public datasets, especially for non-English languages. To address this language resource gap in Chinese, we present ORCHID (Oral Chinese Debate), the first Chinese dataset for benchmarking target-independent stance detection and debate summarization. Our dataset consists of 1,218 real-world debates that were conducted in Chinese on 476 unique topics, containing 2,436 stance-specific summaries and 14,133 fully annotated utterances. Besides providing a versatile testbed for future research, we also conduct an empirical study on the dataset and propose an integrated task. The results show the challenging nature of the dataset and suggest a potential of incorporating stance detection in summarization for argumentative dialogue.",
}

@inproceedings{wang-etal-2023-m3seg,
    title = "{M}$^3${S}eg: A Maximum-Minimum Mutual Information Paradigm for Unsupervised Topic Segmentation in {ASR} Transcripts",
    author = "Wang, Ke  and
      Zhao, Xiutian  and
      Li, Yanghui  and
      Peng, Wei",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.492",
    pages = "7928--7934",
    abstract = "Topic segmentation aims to detect topic boundaries and split automatic speech recognition transcriptions (e.g., meeting transcripts) into segments that are bounded by thematic meanings. In this work, we propose M$^3$Seg, a novel Maximum-Minimum Mutual information paradigm for linear topic segmentation without using any parallel data. Specifically, by employing sentence representations provided by pre-trained language models, M$^3$Seg first learns a region-based segment encoder based on the maximization of mutual information between the global segment representation and the local contextual sentence representation. Secondly, an edge-based boundary detection module aims to segment the whole by topics based on minimizing the mutual information between different segments. Experiment results on two public datasets demonstrate the effectiveness of M$^3$Seg, which outperform the state-of-the-art methods by a significant (18{\%}{--}37{\%} improvement) margin.",
}

@inproceedings{wang-etal-2023-prose,
    title = "{PROSE}: A Pronoun Omission Solution for {C}hinese-{E}nglish Spoken Language Translation",
    author = "Wang, Ke  and
      Zhao, Xiutian  and
      Li, Yanghui  and
      Peng, Wei",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.141",
    pages = "2297--2311",
    abstract = "Neural Machine Translation (NMT) systems encounter a significant challenge when translating a pro-drop ({`}pronoun-dropping{'}) language (e.g., Chinese) to a non-pro-drop one (e.g., English), since the pro-drop phenomenon demands NMT systems to recover omitted pronouns. This unique and crucial task, however, lacks sufficient datasets for benchmarking. To bridge this gap, we introduce PROSE, a new benchmark featured in diverse pro-drop instances for document-level Chinese-English spoken language translation. Furthermore, we conduct an in-depth investigation of the pro-drop phenomenon in spoken Chinese on this dataset, reconfirming that pro-drop reduces the performance of NMT systems in Chinese-English translation. To alleviate the negative impact introduced by pro-drop, we propose Mention-Aware Semantic Augmentation, a novel approach that leverages the semantic embedding of dropped pronouns to augment training pairs. Results from the experiments on four Chinese-English translation corpora show that our proposed method outperforms existing methods regarding omitted pronoun retrieval and overall translation quality.",
}
